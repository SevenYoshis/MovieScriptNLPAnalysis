{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKSx9IUWXIjm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "import stanza\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We allow the program to read in saved tables in order to reduce running time, which can be quite large.\n",
    "recalculate_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gs8GNU0FXHQB"
   },
   "outputs": [],
   "source": [
    "base_path = '.'\n",
    "spreadsheets_path = 'Movie_spreadsheets'\n",
    "data_path = os.path.join(base_path, spreadsheets_path)\n",
    "intermediate_path = os.path.join(base_path, 'intermediate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MQJSiOYbayd"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ER7uuFx8roZv"
   },
   "outputs": [],
   "source": [
    "def split_lines_with_character_tags(df):\n",
    "    df = df.sample(frac=1)\n",
    "    df = df.reset_index(drop=True)\n",
    "    # Remove text which are labeled character names but which are not all caps (which often indicate stage directions)\n",
    "    df['line #'] = df.index\n",
    "    df['line'] = df['line'].str.replace('\\n', ' ')\n",
    "    df = df[df['character'].str.isupper()]\n",
    "    \n",
    "    # Remove parentheticals such as \"(CONTD)\" or \"(V.O.)\"\n",
    "    df['character'] = df['character'].str.replace(r\"\\(.+\\)\", '').str.strip()\n",
    "    df['original character'] = df['character']\n",
    "    df['line'] = df['line'].str.replace(r'\\(cont.+d\\)', '', flags=re.IGNORECASE)\n",
    "    df = df[df['character'].str.strip().str.len() != 0]\n",
    "\n",
    "\n",
    "    for character in df['original character'].unique():\n",
    "        # If the name of a character (ONLY if in all caps, as is expected of character headers)\n",
    "        # appears in a section of speech, separate it into another section of speech.\n",
    "        # This is because we frequently observed one character's speech being contaminated with another's, e.g.:\n",
    "            # SAM: Hi there how's it going? ALICE: I'm doing well\n",
    "            # SAM: Glad to hear it.\n",
    "        while len(df[df['line'].str.contains(re.escape(character))]) > 0:\n",
    "            new_rows = df[df['line'].str.contains(character)].copy()\n",
    "            new_rows.loc[:,'line'] = new_rows['line'].str.split(character).apply(lambda x: x[1])\n",
    "            df.loc[:,'line'] = df['line'].str.split(character).apply(lambda x: x[0])\n",
    "            new_rows['character'] = character\n",
    "            new_rows.loc[:,'line #'] += .001\n",
    "            df = df.append(new_rows)\n",
    "            df = df.sort_values(by='line #').reset_index(drop=True)\n",
    "            df.loc[:, 'line #'] = df.index\n",
    "\n",
    "    df = df.drop('original character', axis=1)        \n",
    "    df['character'] = df['character'].str.replace(r'[^A-z]','')\n",
    "\n",
    "    df ['line'] = df['line'].str.replace('\\r', '')\n",
    "    df['line'] = df['line'].str.replace('\\\\\\'', '\\'')\n",
    "    df = df[df['line'].str.strip().str.len() != 0]\n",
    "    df = df[df['character'].str.strip().str.len() != 0]\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3FxmcEqzyRb"
   },
   "outputs": [],
   "source": [
    "# Silence chained assignment warnings which are incorrect\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "863RuZS8wUPM",
    "outputId": "de188533-2c56-4cc1-b41e-170af7dacc3a"
   },
   "outputs": [],
   "source": [
    "if recalculate_all:\n",
    "    # For every movie in the dataset, run the cleaning function\n",
    "    df = pd.DataFrame()\n",
    "    movie_id = 0\n",
    "    for file in tqdm(sorted(os.listdir(data_path))):\n",
    "        if file.endswith('.csv'):\n",
    "            movie_title = file.replace('.csv', '')\n",
    "            # print(movie_title)\n",
    "            individual_df = pd.read_csv(os.path.join(data_path, file), index_col=0)\n",
    "            # print(file)\n",
    "            # print(individual_df.head())\n",
    "            individual_df['movie_id'] = movie_id\n",
    "            movie_id += 1\n",
    "            individual_df['movie_title'] = movie_title\n",
    "            individual_df = split_lines_with_character_tags(individual_df)\n",
    "            df = df.append(individual_df)\n",
    "\n",
    "    # Weird problem in the labeling of Black Panther\n",
    "    df = df[~df['character'].isin(['T', 'A', 'N'])]\n",
    "    df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "vffFZnXtLAL8",
    "outputId": "a8c895f6-db0e-4dd8-9799-7a9a9f5fade3"
   },
   "outputs": [],
   "source": [
    "if recalculate_all:\n",
    "    # Find the number of lines per character\n",
    "    character_counts = pd.DataFrame(df.groupby(['character', 'movie_title'])['line #'].count())\n",
    "    character_counts.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "i1D4qSMiL5iR",
    "outputId": "04b05533-ebc5-43a1-f2ec-962df3f3963d"
   },
   "outputs": [],
   "source": [
    "if recalculate_all:\n",
    "    top_character_counts = character_counts[character_counts['line #'] >= 60]\n",
    "    bottom_character_counts = character_counts[character_counts['line #'] <= 60]\n",
    "    top_character_counts.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RpzUucryMEYQ"
   },
   "outputs": [],
   "source": [
    "if recalculate_all:\n",
    "    # Drop any characters who have less than 60 lines\n",
    "    for character, movie in tqdm(bottom_character_counts.index):\n",
    "        df = df[~((df['character'] == character) & (df['movie_title'] == movie))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCaTAn2ViOxK"
   },
   "source": [
    "# Sentiment Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the stanford Stanza library to assign a sentiment score to every line. The library assigns sentiment scores for each sentence (0, 1, or 2). If a line contains multiple sentences, we take the average (mean) sentiment of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292,
     "referenced_widgets": [
      "917d2d7d844c463d80927763abef0685",
      "1ca4261c3a0b486d8c1a758f350bb94f",
      "6a8f1f7ed6044ae187ad67d5e6ecaa82",
      "39eee27f778d41f1bc1229863f0da9a8",
      "544a5c3e0c8c4c7ca3b290c9be181746",
      "6fff69c04e2e443f9b13fc4b89b9bd2d",
      "45e21e44d94e42f58568633f5572a1e3",
      "12b52e57d9ef4bd19f01e0f38d42f3fe",
      "1722a5f257aa41b290e59eebe471d4ef",
      "48914257e64644caa249ee54acdd8452",
      "c35ffb80167245b58537c52e030a3933"
     ]
    },
    "id": "DRQQVIfbSdIN",
    "outputId": "1610b6a1-6c41-4c54-ec49-31a91b4e0c97"
   },
   "outputs": [],
   "source": [
    "if recalculate_all:\n",
    "    stanza.download('en')\n",
    "    nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment', use_gpu=False)\n",
    "\n",
    "    def sentiment_score(text):\n",
    "        doc = nlp(text)\n",
    "        scores = []\n",
    "        for i, sentence in enumerate(doc.sentences):\n",
    "            scores.append(sentence.sentiment)\n",
    "        return np.mean(scores)\n",
    "    \n",
    "    df['sentiment'] = df['line'].progress_apply(sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oEYZwCJ-_TfN",
    "outputId": "8a956470-ea89-4f17-b636-5f08ea4b8a44"
   },
   "outputs": [],
   "source": [
    "# Get a new line ID which gives the position of the line in the whole movie, not simply in the character's lines\n",
    "# This enables us to know, for example, whether a line occurred in the beginning or end of the movie\n",
    "# rather than just in the beginning or end of a character's own dialog\n",
    "if recalculate_all:\n",
    "    df['movie_length'] = 0\n",
    "    for movie_id in tqdm(df['movie_id']):\n",
    "        movie_length = df.loc[df['movie_id'] == movie_id]['line #'].max()\n",
    "        df.loc[df['movie_id'] == movie_id, 'movie_length'] = movie_length\n",
    "    df['relative_line_id'] = df['line #'] / df['movie_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_6tZmnSMFtQ"
   },
   "outputs": [],
   "source": [
    "# Assign an index which contains both the character and movie name. \n",
    "# If we did not elect to recalculate everything, we now load in the existing sentiment scores\n",
    "if recalculate_all:\n",
    "    df['combined_name'] = df['movie_title'].str.cat(df['character'], sep='_')\n",
    "    df.to_csv(os.path.join(intermediate_path, 'movie_df_shuffle.csv'))\n",
    "else:\n",
    "    df = pd.read_csv(os.path.join(intermediate_path, 'movie_df_shuffle.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHwqWnfaFrYQ"
   },
   "outputs": [],
   "source": [
    "if recalculate_all:\n",
    "    expanded_movie_size = df['movie_length'].max()\n",
    "    sentiment_df = np.ones(shape=(len(df['combined_name'].unique()), expanded_movie_size))\n",
    "    sentiment_df = pd.DataFrame(sentiment_df)\n",
    "    sentiment_df.index = df['combined_name'].unique()\n",
    "\n",
    "    # Arbitrarily mark cells whose sentiment scores did not originate from the movie dataframe.\n",
    "    # True sentiment scores cannot be less than 0\n",
    "    sentiment_df = sentiment_df * -10\n",
    "    \n",
    "    # We standardize the length of movies by assigning each line to the index of its relative position in the movie \n",
    "    # (e.g. 66% of the way through) to its position in the expanded standardized movie length\n",
    "    # e.g. if the longest movie had 5000 lines, a line at 66% of the way through its own movie\n",
    "    # would be assigned to position 3300 in its new \"relative\" movie length\n",
    "    for row in df.iterrows():\n",
    "        sentiment_df.loc[row[1]['combined_name'], np.round(row[1]['relative_line_id'] * (expanded_movie_size - 1))] = row[1]['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ne_E4r6IQqgC",
    "outputId": "cc51bd91-68f0-4e6f-a84d-f153e17b6188"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def expand_row(row):\n",
    "    # To allow comparison, we needed to fill in the empty values where character was not speaking. We elected to \n",
    "    # maintain the character's previous sentiment for all non-speaking lines, adding some gaussian noise\n",
    "    std = row[row != -10].std()\n",
    "    if row[0] == -10:\n",
    "        first_nonempty_index = row[row != -10].index[0]\n",
    "        first_nonempty_value = row[row != -10].loc[first_nonempty_index]\n",
    "        gaussian_noise = np.random.normal(0, std / 5, size=first_nonempty_index)\n",
    "        row[:first_nonempty_index] = first_nonempty_value + gaussian_noise\n",
    "    for i in range(len(row)):\n",
    "        if row[i] == -10:\n",
    "            gaussian_noise = np.random.normal(0, std / 5)\n",
    "            row[last_index:i+1] = last_val + gaussian_noise\n",
    "        last_index = i\n",
    "        last_val = row[i]\n",
    "    # Standardize each character's arc to have a mean of 0 and a standard deviation of 1\n",
    "    std = row[row != -10].std()\n",
    "    row = (row - row.mean()) / std\n",
    "\n",
    "    return row\n",
    "        \n",
    "if recalculate_all:\n",
    "    sentiment_df = sentiment_df.progress_apply(expand_row, axis=1)\n",
    "    sentiment_df.to_csv(os.path.join(intermediate_path, 'sentiment_df_shuffle.csv'))\n",
    "else:\n",
    "    sentiment_df = pd.read_csv(os.path.join(intermediate_path, 'sentiment_df_shuffle.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform principal component analysis for dimensionality reduction to inspect for visible clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Md14fv3lcqp"
   },
   "outputs": [],
   "source": [
    "pca = PCA(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For PCA, we use a very small smoothing window (3 timepoints across) to reduce noise\n",
    "rolling_df = sentiment_df.rolling(3, axis=1).mean().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx8JCARnltbV"
   },
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(pca.fit_transform(rolling_df))\n",
    "pca_df.index = rolling_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the standard deviation of all movies across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "ngXIsMw2nI8U",
    "outputId": "61f62c6b-6871-48cf-f028-fdcef57240d1"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x=sentiment_df.columns, y=sentiment_df.std(), mode='lines'))\n",
    "# fig = go.Scatter()\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"σ of Sentiment\",\n",
    "                  )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the average sentiment over time for all characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "MdLqKisIlsWM",
    "outputId": "e7755b30-7b32-481d-909f-3a89500abbbf"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x=sentiment_df.columns, y=sentiment_df.mean().rolling(30).mean(), mode='lines'))\n",
    "# fig = go.Scatter()\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  ) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All characters' first two principal components visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "H_VhoUtDmByW",
    "outputId": "6eb301b0-dcf2-41e4-bb39-307eb7de6eef"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(pca_df.reset_index(), 0, 1, hover_name='index', width=650, height=500)\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"PC0\",\n",
    "    yaxis_title=\"PC1\",\n",
    "\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWDVsNLVRZSZ"
   },
   "source": [
    "#### First Principal Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aG5rveHFa-F2"
   },
   "outputs": [],
   "source": [
    "midpoint = len(sentiment_df) // 2\n",
    "\n",
    "def melt_sentiment_df(df):\n",
    "    return pd.melt(df.reset_index(), id_vars='index').rename({'index': 'Character', 'variable': 'Time', 'value': 'Sentiment'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "B0djLVTEGLF_",
    "outputId": "2c821edc-166a-4da1-a8b3-cfb8f4763467"
   },
   "outputs": [],
   "source": [
    "\n",
    "temp_df = sentiment_df.loc[pca_df.sort_values(0).iloc[-5:].index]\n",
    "fig = go.Figure()\n",
    "for index in temp_df.index:\n",
    "    fig.add_trace(go.Scatter(x=temp_df.columns, y=temp_df.loc[index],\n",
    "                    mode='lines'))\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  ) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "-uV2_ppkGmRb",
    "outputId": "3ad82785-9c5a-4acd-fcb1-3f74e241f2f6"
   },
   "outputs": [],
   "source": [
    "temp_df = sentiment_df.loc[pca_df.sort_values(0).iloc[midpoint-2:midpoint+3].index]\n",
    "fig = go.Figure()\n",
    "for index in temp_df.index:\n",
    "    fig.add_trace(go.Scatter(x=temp_df.columns, y=temp_df.loc[index],\n",
    "                    mode='lines'))\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  ) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "vazW2rbpGoS3",
    "outputId": "d3b351e0-4364-45de-b3ef-8397e17af19f"
   },
   "outputs": [],
   "source": [
    "temp_df = sentiment_df.loc[pca_df.sort_values(0).iloc[:5].index]\n",
    "fig = go.Figure()\n",
    "for index in temp_df.index:\n",
    "    fig.add_trace(go.Scatter(x=temp_df.columns, y=temp_df.loc[index],\n",
    "                    mode='lines'))\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  ) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iX-pF_ngGvpY"
   },
   "source": [
    "#### Second Principal Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "mPrZgCayGq9B",
    "outputId": "70ac7802-14ec-4c97-ba2d-34b8646e19b9"
   },
   "outputs": [],
   "source": [
    "temp_df = sentiment_df.loc[pca_df.sort_values(1).iloc[-5:].index]\n",
    "fig = go.Figure()\n",
    "for index in temp_df.index:\n",
    "    fig.add_trace(go.Scatter(x=temp_df.columns, y=temp_df.loc[index],\n",
    "                    mode='lines'))\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  ) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "gw8vhiaHGyKM",
    "outputId": "56c41aa4-dd48-496f-c7ee-2295147eb892"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "temp_df = sentiment_df.loc[pca_df.sort_values(1).iloc[midpoint-2:midpoint+3].index]\n",
    "fig = go.Figure()\n",
    "for index in temp_df.index:\n",
    "    fig.add_trace(go.Scatter(x=temp_df.columns, y=temp_df.loc[index],\n",
    "                    mode='lines'))\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "pBCrumWGG8kl",
    "outputId": "e530d298-f89f-4602-bea0-89f8542c96d2"
   },
   "outputs": [],
   "source": [
    "temp_df = sentiment_df.loc[pca_df.sort_values(1).iloc[:5].index]\n",
    "fig = go.Figure()\n",
    "for index in temp_df.index:\n",
    "    fig.add_trace(go.Scatter(x=temp_df.columns, y=temp_df.loc[index],\n",
    "                    mode='lines'))\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  ) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "996EpVT4l5DX",
    "outputId": "b58fd720-68f0-4bc6-f042-77c5e2bec6c8"
   },
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# tsne = TSNE( learning_rate='auto', init='pca')\n",
    "# tsne_df = pd.DataFrame(tsne.fit_transform(sentiment_df.rolling(200, min_periods=1, axis=1).mean().dropna(axis=1)))\n",
    "# tsne_df['ix'] = sentiment_df.index\n",
    "\n",
    "# px.scatter(tsne_df, x=0, y=1, hover_name='ix').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkzFDEWr93dY"
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce noise, we will use a sliding, smoothing window of length 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_sentiment_df = sentiment_df.rolling(rolling_window, axis=1, center=True).mean().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one distance metric, we use dynamic time warping, which should be invariant to small translations in the exact timing of patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpzFoG3PcLkZ"
   },
   "outputs": [],
   "source": [
    "if recalculate_all:\n",
    "    from tslearn.metrics import cdist_dtw as dtw\n",
    "    distances = dtw(sentiment_df, n_jobs=-1, verbose=50)\n",
    "\n",
    "    dtw_df = pd.DataFrame(distances)\n",
    "    dtw_df.index = sentiment_df.index\n",
    "    dtw_df.columns = sentiment_df.index\n",
    "\n",
    "    dtw_df.to_csv(os.path.join(intermediate_path, 'distances_shuffle.csv'))\n",
    "else:\n",
    "    dtw_df = pd.read_csv(os.path.join(intermediate_path, 'distances_shuffle.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subplot_dimensions(n):\n",
    "    return (int(np.ceil(n / 3)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We settled on 9 clusters as a minimum of the optimal clusterings from all of our models\n",
    "n_clusters=9\n",
    "\n",
    "def cluster(data, model):\n",
    "    \"\"\"\n",
    "    This function helps to calculate and visualize clusters using whatever\n",
    "    clustering model is passed in\n",
    "    \"\"\"\n",
    "    visualizer = KElbowVisualizer(model, k=(2,30), timings=False)\n",
    "    visualizer.fit(data)        # Fit data to visualizer\n",
    "    visualizer.show()\n",
    "    # n_clusters = visualizer.elbow_value_\n",
    "    \n",
    "    model.set_params(n_clusters=n_clusters)\n",
    "    cluster_df = pd.Series(model.fit_predict(data), index=sentiment_df.index)\n",
    "    cluster_df = cluster_df.rename({0: 'cluster'})\n",
    "    clusters = cluster_df.unique()\n",
    "    clusters.sort()\n",
    "    rows, cols = find_subplot_dimensions(n_clusters)\n",
    "    outer_fig = make_subplots(\n",
    "        rows=rows, \n",
    "        cols=cols, \n",
    "        shared_xaxes='all', \n",
    "        shared_yaxes='all',\n",
    "        x_title='Time',\n",
    "        y_title='Sentiment',\n",
    "        horizontal_spacing=0.03,\n",
    "        vertical_spacing=0.05,\n",
    "        subplot_titles=([\"Cluster {}\".format(i) for i in range(n_clusters)])\n",
    "    )\n",
    "    outer_fig.update_layout(showlegend=False, \n",
    "                    width=(cols+1)*200, \n",
    "                    height=(rows+1)*200,\n",
    "                )\n",
    "\n",
    "    \n",
    "    plotted_count = 0\n",
    "    \n",
    "    for i in range(1, rows+1):\n",
    "        for j in range(1, cols+1):\n",
    "            if plotted_count < n_clusters:\n",
    "                indices = cluster_df[cluster_df == plotted_count].dropna().index\n",
    "                temp_df = rolling_sentiment_df.loc[indices]\n",
    "                for index in temp_df.index:\n",
    "                    outer_fig.append_trace(\n",
    "                        go.Scatter(\n",
    "                            x=temp_df.columns, y=temp_df.loc[index],\n",
    "                            mode='lines',\n",
    "                            # text=index, \n",
    "                            marker=dict(\n",
    "                                color='rgba(135, 206, 250, 0.8)',\n",
    "                            ),\n",
    "                            hoverinfo='none',\n",
    "                            ), \n",
    "                        i, \n",
    "                        j)\n",
    "                outer_fig.append_trace(\n",
    "                    go.Scatter(\n",
    "                        x=temp_df.columns, y=temp_df.mean(),\n",
    "                        mode='lines',\n",
    "                        marker=dict(\n",
    "                            color='rgba(128, 128, 128, .8)',\n",
    "                        ),\n",
    "                    ), \n",
    "                    i, \n",
    "                    j\n",
    "                )\n",
    "                plotted_count += 1\n",
    "    outer_fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(\n",
    "        title=dict(\n",
    "            text='Sentiment'\n",
    "        )\n",
    "    )\n",
    "    outer_fig.show()\n",
    "    return cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(base_path, 'clusters_shuffle.csv')):\n",
    "    clusters_df = pd.DataFrame(index=sentiment_df.index)\n",
    "else:\n",
    "    clusters_df = pd.read_csv(os.path.join(base_path, 'clusters_shuffle.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering()\n",
    "clusters_df['euclidean_sentiment'] = cluster(rolling_sentiment_df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering(linkage='complete', affinity='manhattan')\n",
    "clusters_df['manhattan_sentiment'] = cluster(rolling_sentiment_df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the differences between each timepoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = rolling_sentiment_df.diff(axis=1).dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering()\n",
    "clusters_df['euclidean_diff'] = cluster(diff_df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering(linkage='complete', affinity='manhattan')\n",
    "clusters_df['manhattan_diff'] = cluster(diff_df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On dynamic time warp distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering(affinity='precomputed', linkage='complete')\n",
    "clusters_df['dtw_sentiment'] = cluster(dtw_df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the gold standard clusterings and standardize their formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard_df = pd.read_json(os.path.join(base_path, 'tvtropes.clusters.json')).T.drop('id', axis=1)\n",
    "gold_standard_df.sort_values('movie')\n",
    "gold_standard_df.to_csv(os.path.join(base_path, 'gold_standard.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'gold_standard_cluster' in clusters_df.columns:\n",
    "    clusters_df['gold_standard_cluster'] = '0' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for loc in clusters_df.index:\n",
    "    if not pd.isna(clusters_df.loc[loc, 'gold_standard_cluster']) and clusters_df.loc[loc, 'gold_standard_cluster'] == '0':\n",
    "        mapping = input(loc)\n",
    "        clusters_df.loc[loc, 'gold_standard_cluster'] = mapping\n",
    "        clusters_df.to_csv(os.path.join(base_path, 'clusters_shuffle.csv'))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 77 characters who appear in both datasets (have both inferred and gold standard clusterings):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df[~clusters_df['gold_standard_cluster'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Purities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "According to Bamman et al. 2013 cluster purity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "purity_df = clusters_df.copy().dropna()\n",
    "value_counts = purity_df.value_counts('gold_standard_cluster')\n",
    "supported_clusters = value_counts.where(value_counts > 1).dropna().index.to_list()\n",
    "purity_df[purity_df['gold_standard_cluster'].isin(supported_clusters)].value_counts('gold_standard_cluster')\n",
    "\n",
    "clusterings = purity_df.columns.to_list()\n",
    "clusterings.remove('gold_standard_cluster')\n",
    "\n",
    "purities = {}\n",
    "\n",
    "for clustering in clusterings:\n",
    "    purity = pd.crosstab(purity_df[clustering], purity_df['gold_standard_cluster']).max().sum() / len(purity_df)\n",
    "    purities[clustering] = purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline cluster purities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning each character randomly to a cluster based on the proportion of that cluster in the original clustering (According to Bamman et al. 2013 baseline methodology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_distributions_df = pd.DataFrame([clusters_df[clustering].value_counts().sort_index() / len(clusters_df) for clustering in clusterings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "purity_baseline_df = purity_df.copy()\n",
    "for clustering in clusterings:\n",
    "    purity_baseline_df[clustering] = np.random.choice(n_clusters, size=len(purity_baseline_df), p=cluster_distributions_df.loc[clustering])\n",
    "    \n",
    "baseline_purities = {}\n",
    "\n",
    "for clustering in clusterings:\n",
    "    purity = pd.crosstab(purity_baseline_df[clustering], purity_baseline_df['gold_standard_cluster']).max().sum() / len(purity_baseline_df)\n",
    "    baseline_purities[clustering] = purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_purities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual inspection of gold-standard clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoners = purity_df[purity_df['gold_standard_cluster'] == 'stoner'].index.to_list()\n",
    "print(stoners)\n",
    "fig = go.Figure()\n",
    "for stoner in stoners:\n",
    "    temp_df = rolling_sentiment_df.loc[stoner]\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x=temp_df.index, y=temp_df.values,\n",
    "            mode='lines',\n",
    "            # text=index, \n",
    "            marker=dict(\n",
    "                color='rgba(135, 206, 250, 0.8)',\n",
    "            ),\n",
    "            hoverinfo='none',\n",
    "            ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purity_df[purity_df['gold_standard_cluster'].isin(supported_clusters)].value_counts('gold_standard_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoners = purity_df[purity_df['gold_standard_cluster'] == 'stoner'].index.to_list()\n",
    "print(stoners)\n",
    "fig = go.Figure()\n",
    "for stoner in stoners:\n",
    "    temp_df = rolling_sentiment_df.loc[stoner]\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x=temp_df.index, y=temp_df.values,\n",
    "            mode='lines',\n",
    "            # text=index, \n",
    "            marker=dict(\n",
    "                color='rgba(135, 206, 250, 0.8)',\n",
    "            ),\n",
    "            hoverinfo='none',\n",
    "            ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoners = purity_df[purity_df['gold_standard_cluster'] == 'crazy_jealous_guy'].index.to_list()\n",
    "print(stoners)\n",
    "fig = go.Figure()\n",
    "for stoner in stoners:\n",
    "    temp_df = rolling_sentiment_df.loc[stoner]\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x=temp_df.index, y=temp_df.values,\n",
    "            mode='lines',\n",
    "            # text=index, \n",
    "            marker=dict(\n",
    "                color='rgba(135, 206, 250, 0.8)',\n",
    "            ),\n",
    "            hoverinfo='none',\n",
    "            ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoners = purity_df[purity_df['gold_standard_cluster'] == 'stupid_crooks'].index.to_list()\n",
    "print(stoners)\n",
    "fig = go.Figure()\n",
    "for stoner in stoners:\n",
    "    temp_df = rolling_sentiment_df.loc[stoner]\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x=temp_df.index, y=temp_df.values,\n",
    "            mode='lines',\n",
    "            # text=index, \n",
    "            marker=dict(\n",
    "                color='rgba(135, 206, 250, 0.8)',\n",
    "            ),\n",
    "            hoverinfo='none',\n",
    "            ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoners = purity_df[purity_df['gold_standard_cluster'] == 'loveable_rogue'].index.to_list()\n",
    "print(stoners)\n",
    "fig = go.Figure()\n",
    "for stoner in stoners:\n",
    "    temp_df = rolling_sentiment_df.loc[stoner]\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x=temp_df.index, y=temp_df.values,\n",
    "            mode='lines',\n",
    "            # text=index, \n",
    "            marker=dict(\n",
    "                color='rgba(135, 206, 250, 0.8)',\n",
    "            ),\n",
    "            hoverinfo='none',\n",
    "            ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12b52e57d9ef4bd19f01e0f38d42f3fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1722a5f257aa41b290e59eebe471d4ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1ca4261c3a0b486d8c1a758f350bb94f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fff69c04e2e443f9b13fc4b89b9bd2d",
      "placeholder": "​",
      "style": "IPY_MODEL_45e21e44d94e42f58568633f5572a1e3",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json: "
     }
    },
    "39eee27f778d41f1bc1229863f0da9a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48914257e64644caa249ee54acdd8452",
      "placeholder": "​",
      "style": "IPY_MODEL_c35ffb80167245b58537c52e030a3933",
      "value": " 142k/? [00:00&lt;00:00, 3.93MB/s]"
     }
    },
    "45e21e44d94e42f58568633f5572a1e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48914257e64644caa249ee54acdd8452": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "544a5c3e0c8c4c7ca3b290c9be181746": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a8f1f7ed6044ae187ad67d5e6ecaa82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12b52e57d9ef4bd19f01e0f38d42f3fe",
      "max": 24459,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1722a5f257aa41b290e59eebe471d4ef",
      "value": 24459
     }
    },
    "6fff69c04e2e443f9b13fc4b89b9bd2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "917d2d7d844c463d80927763abef0685": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ca4261c3a0b486d8c1a758f350bb94f",
       "IPY_MODEL_6a8f1f7ed6044ae187ad67d5e6ecaa82",
       "IPY_MODEL_39eee27f778d41f1bc1229863f0da9a8"
      ],
      "layout": "IPY_MODEL_544a5c3e0c8c4c7ca3b290c9be181746"
     }
    },
    "c35ffb80167245b58537c52e030a3933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
