{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sKSx9IUWXIjm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "import stanza\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We allow the program to read in saved tables in order to reduce running time, which can be quite large.\n",
    "recalculate_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gs8GNU0FXHQB"
   },
   "outputs": [],
   "source": [
    "base_path = '.'\n",
    "spreadsheets_path = 'Movie_spreadsheets'\n",
    "data_path = os.path.join(base_path, spreadsheets_path)\n",
    "intermediate_path = os.path.join(base_path, 'intermediate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MQJSiOYbayd"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ER7uuFx8roZv"
   },
   "outputs": [],
   "source": [
    "def split_lines_with_character_tags(df):\n",
    "    # Remove text which are labeled character names but which are not all caps (which often indicate stage directions)\n",
    "    df['line #'] = df.index\n",
    "    df['line'] = df['line'].str.replace('\\n', ' ', regex=True)\n",
    "    df = df[df['character'].str.isupper()]\n",
    "    \n",
    "    # Remove parentheticals such as \"(CONTD)\" or \"(V.O.)\"\n",
    "    df['character'] = df['character'].str.replace(r\"\\(.+\\)\", '', regex=True).str.strip()\n",
    "    df['original character'] = df['character']\n",
    "    df['line'] = df['line'].str.replace(r'\\(cont.+d\\)', '', flags=re.IGNORECASE, regex=True)\n",
    "    df = df[df['character'].str.strip().str.len() != 0]\n",
    "\n",
    "\n",
    "    for character in df['original character'].unique():\n",
    "        # If the name of a character (ONLY if in all caps, as is expected of character headers)\n",
    "        # appears in a section of speech, separate it into another section of speech.\n",
    "        # This is because we frequently observed one character's speech being contaminated with another's, e.g.:\n",
    "            # SAM: Hi there how's it going? ALICE: I'm doing well\n",
    "            # SAM: Glad to hear it.\n",
    "        while len(df[df['line'].str.contains(re.escape(character), regex=True)]) > 0:\n",
    "            new_rows = df[df['line'].str.contains(character, regex=True)].copy()\n",
    "            new_rows.loc[:,'line'] = new_rows['line'].str.split(character).apply(lambda x: x[1])\n",
    "            df.loc[:,'line'] = df['line'].str.split(character).apply(lambda x: x[0])\n",
    "            new_rows['character'] = character\n",
    "            new_rows.loc[:,'line #'] += .001\n",
    "            df = df.append(new_rows)\n",
    "            df = df.sort_values(by='line #').reset_index(drop=True)\n",
    "            df.loc[:, 'line #'] = df.index\n",
    "\n",
    "    df = df.drop('original character', axis=1)        \n",
    "    df['character'] = df['character'].str.replace(r'[^A-z]','', regex=True)\n",
    "\n",
    "    df ['line'] = df['line'].str.replace('\\r', '', regex=True)\n",
    "    df['line'] = df['line'].str.replace('\\\\\\'', '\\'', regex=True)\n",
    "    df = df[df['line'].str.strip().str.len() != 0]\n",
    "    df = df[df['character'].str.strip().str.len() != 0]\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w3FxmcEqzyRb"
   },
   "outputs": [],
   "source": [
    "# Silence chained assignment warnings which are incorrect\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "863RuZS8wUPM",
    "outputId": "de188533-2c56-4cc1-b41e-170af7dacc3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 90/90 [00:04<00:00, 19.32it/s]\n"
     ]
    }
   ],
   "source": [
    "if recalculate_all:\n",
    "    # For every movie in the dataset, run the cleaning function\n",
    "    df = pd.DataFrame()\n",
    "    movie_id = 0\n",
    "    for file in tqdm(sorted(os.listdir(data_path))):\n",
    "        if file.endswith('.csv'):\n",
    "            movie_title = file.replace('.csv', '')\n",
    "            # print(movie_title)\n",
    "            individual_df = pd.read_csv(os.path.join(data_path, file), index_col=0)\n",
    "            # print(file)\n",
    "            # print(individual_df.head())\n",
    "            individual_df['movie_id'] = movie_id\n",
    "            movie_id += 1\n",
    "            individual_df['movie_title'] = movie_title\n",
    "            individual_df = split_lines_with_character_tags(individual_df)\n",
    "            df = df.append(individual_df)\n",
    "\n",
    "    # Weird problem in the labeling of Black Panther\n",
    "    df = df[~df['character'].isin(['T', 'A', 'N'])]\n",
    "    df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "vffFZnXtLAL8",
    "outputId": "a8c895f6-db0e-4dd8-9799-7a9a9f5fade3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if recalculate_all:\n",
    "    # Find the number of lines per character\n",
    "    character_counts = pd.DataFrame(df.groupby(['character', 'movie_title'])['line #'].count())\n",
    "    character_counts.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "i1D4qSMiL5iR",
    "outputId": "04b05533-ebc5-43a1-f2ec-962df3f3963d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if recalculate_all:\n",
    "    top_character_counts = character_counts[character_counts['line #'] >= 60]\n",
    "    bottom_character_counts = character_counts[character_counts['line #'] <= 60]\n",
    "    top_character_counts.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 3833/3833 [00:35<00:00, 108.81it/s]\n"
     ]
    }
   ],
   "source": [
    "if recalculate_all:\n",
    "    # Drop any characters who have less than 60 lines\n",
    "    for character, movie in tqdm(bottom_character_counts.index):\n",
    "        df = df[~((df['character'] == character) & (df['movie_title'] == movie))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "import string\n",
    "\n",
    "class Markov:\n",
    "    \n",
    "    def __init__(self, lines):\n",
    "        self.lines = lines\n",
    "        self.bigram_dict = {}\n",
    "        self.bos = '<bos>'\n",
    "        self.eos = '<eos>'\n",
    "        \n",
    "    def process_line(self, text):\n",
    "        text = re.sub(r'\\'\\'', '', text)\n",
    "        text = re.sub(r'\"', '', text)\n",
    "        \n",
    "                            \n",
    "        tokenized = word_tokenize(text)\n",
    "        \n",
    "        if len(tokenized) == 0:\n",
    "            return []\n",
    "        \n",
    "        tokenized[0] = tokenized[0].lower() \n",
    "                    \n",
    "        tokenized.insert(0, self.bos)\n",
    "        \n",
    "        # List iteration based on code from StackOverflow user John La Rooy https://stackoverflow.com/a/6022822\n",
    "        i = 1\n",
    "        \n",
    "                \n",
    "        while i < len(tokenized):\n",
    "            tokenized[i] = tokenized[i].lower()\n",
    "            word = tokenized[i] \n",
    "            if '\\'' in word:\n",
    "                del tokenized[i]\n",
    "                tokenized[i-1] += word   \n",
    "            else:\n",
    "                if word == '.' or word == '?' or word == '!':\n",
    "                    tokenized.insert(i+1, self.eos)\n",
    "                    if (i + 2) < len(tokenized):\n",
    "                        tokenized.insert(i + 2, self.bos)\n",
    "                i+=1\n",
    "        \n",
    "        if tokenized[-1] != self.eos:\n",
    "            tokenized.append(self.eos)\n",
    "        return tokenized\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        tokenized = lines.apply(self.process_line)\n",
    "        for line in tokenized:\n",
    "            for i in range(len(line)-1):\n",
    "                word = line[i]\n",
    "                next_word = line[i+1]\n",
    "                \n",
    "                if word in self.bigram_dict:\n",
    "                    self.bigram_dict[word].append(next_word)\n",
    "                else:\n",
    "                    self.bigram_dict[word] = [next_word]\n",
    "        \n",
    "    \n",
    "    def generate(self, n_tokens):\n",
    "        generated = 0\n",
    "        text = ''\n",
    "        \n",
    "        # terminals = r'[' + re.escape['!?.'] + r']'\n",
    "        while generated < max(1, n_tokens):\n",
    "            token = self.bos\n",
    "            while token != self.eos:\n",
    "                token = np.random.choice(self.bigram_dict[token])\n",
    "                if re.match(r'[\\.\\!\\?,-]', token):\n",
    "                    text += token        \n",
    "                    generated += 1\n",
    "                elif token != self.bos and token != self.eos:\n",
    "                    text+= ' ' + token\n",
    "                    generated += 1\n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 328/328 [00:39<00:00,  8.33it/s]\n"
     ]
    }
   ],
   "source": [
    "if recalculate_all:\n",
    "    for character, movie_id in tqdm(df.groupby(['character', 'movie_id']).count().index):\n",
    "        lines = df[(df['character'] == character) & (df['movie_id'] == movie_id)]['line']\n",
    "        markov = Markov(lines)\n",
    "        markov.train()\n",
    "        for index, row in lines.iteritems():\n",
    "            line_word_count = len(row.split())\n",
    "            df.at[index, 'line'] = markov.generate(line_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCaTAn2ViOxK"
   },
   "source": [
    "# Sentiment Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the stanford Stanza library to assign a sentiment score to every line. The library assigns sentiment scores for each sentence (0, 1, or 2). If a line contains multiple sentences, we take the average (mean) sentiment of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292,
     "referenced_widgets": [
      "917d2d7d844c463d80927763abef0685",
      "1ca4261c3a0b486d8c1a758f350bb94f",
      "6a8f1f7ed6044ae187ad67d5e6ecaa82",
      "39eee27f778d41f1bc1229863f0da9a8",
      "544a5c3e0c8c4c7ca3b290c9be181746",
      "6fff69c04e2e443f9b13fc4b89b9bd2d",
      "45e21e44d94e42f58568633f5572a1e3",
      "12b52e57d9ef4bd19f01e0f38d42f3fe",
      "1722a5f257aa41b290e59eebe471d4ef",
      "48914257e64644caa249ee54acdd8452",
      "c35ffb80167245b58537c52e030a3933"
     ]
    },
    "id": "DRQQVIfbSdIN",
    "outputId": "1610b6a1-6c41-4c54-ec49-31a91b4e0c97"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86e2397140549ceb76ea643187f9f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 10:56:35 INFO: Downloading default packages for language: en (English)...\n",
      "2021-11-30 10:56:37 INFO: File exists: /Users/aaron/stanza_resources/en/default.zip.\n",
      "2021-11-30 10:56:40 INFO: Finished downloading models and saved to /Users/aaron/stanza_resources.\n",
      "2021-11-30 10:56:40 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2021-11-30 10:56:40 INFO: Use device: cpu\n",
      "2021-11-30 10:56:40 INFO: Loading: tokenize\n",
      "2021-11-30 10:56:40 INFO: Loading: sentiment\n",
      "2021-11-30 10:56:40 INFO: Done loading processors!\n",
      "  0%|                                                      | 0/54174 [00:00<?, ?it/s]/Users/aaron/opt/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning:\n",
      "\n",
      "Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "\n",
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      " 18%|███████▌                                   | 9529/54174 [02:53<13:32, 54.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bm/d9v0816x3r59w52nwc2k0vbr0000gn/T/ipykernel_11920/2750255036.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'line'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1100\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bm/d9v0816x3r59w52nwc2k0vbr0000gn/T/ipykernel_11920/2750255036.py\u001b[0m in \u001b[0;36msentiment_score\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentiment_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    229\u001b[0m         assert any([isinstance(doc, str), isinstance(doc, list),\n\u001b[1;32m    230\u001b[0m                     isinstance(doc, Document)]), 'input should be either str, list or Document'\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbulk_process\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbulk\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/stanza/pipeline/tokenize_processor.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# get dict data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         _, _, _, document = output_predictions(None, self.trainer, batches, self.vocab, None,\n\u001b[0m\u001b[1;32m     88\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max_seqlen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTokenizeProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_SEQ_LENGTH_DEFAULT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                                                \u001b[0morig_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/stanza/models/tokenization/utils.py\u001b[0m in \u001b[0;36moutput_predictions\u001b[0;34m(output_file, trainer, data_generator, vocab, mwt_dict, max_seqlen, orig_text, no_ssplit, use_regex_tokens)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0meval_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchparas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/stanza/models/tokenization/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/stanza/models/tokenization/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, feats)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv_res'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    680\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if recalculate_all:\n",
    "    stanza.download('en')\n",
    "    nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment', use_gpu=False)\n",
    "\n",
    "    def sentiment_score(text):\n",
    "        doc = nlp(text)\n",
    "        scores = []\n",
    "        for i, sentence in enumerate(doc.sentences):\n",
    "            scores.append(sentence.sentiment)\n",
    "        return np.mean(scores)\n",
    "    \n",
    "    df['sentiment'] = df['line'].progress_apply(sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oEYZwCJ-_TfN",
    "outputId": "8a956470-ea89-4f17-b636-5f08ea4b8a44"
   },
   "outputs": [],
   "source": [
    "# Get a new line ID which gives the position of the line in the whole movie, not simply in the character's lines\n",
    "# This enables us to know, for example, whether a line occurred in the beginning or end of the movie\n",
    "# rather than just in the beginning or end of a character's own dialog\n",
    "if recalculate_all:\n",
    "    df['movie_length'] = 0\n",
    "    for movie_id in tqdm(df['movie_id']):\n",
    "        movie_length = df.loc[df['movie_id'] == movie_id]['line #'].max()\n",
    "        df.loc[df['movie_id'] == movie_id, 'movie_length'] = movie_length\n",
    "    df['relative_line_id'] = df['line #'] / df['movie_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_6tZmnSMFtQ"
   },
   "outputs": [],
   "source": [
    "# Assign an index which contains both the character and movie name. \n",
    "# If we did not elect to recalculate everything, we now load in the existing sentiment scores\n",
    "if recalculate_all:\n",
    "    df['combined_name'] = df['movie_title'].str.cat(df['character'], sep='_')\n",
    "    df.to_csv(os.path.join(intermediate_path, 'movie_df_markov.csv'))\n",
    "else:\n",
    "    df = pd.read_csv(os.path.join(intermediate_path, 'movie_df_markov.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHwqWnfaFrYQ"
   },
   "outputs": [],
   "source": [
    "if recalculate_all:\n",
    "    expanded_movie_size = df['movie_length'].max()\n",
    "    sentiment_df = np.ones(shape=(len(df['combined_name'].unique()), expanded_movie_size))\n",
    "    sentiment_df = pd.DataFrame(sentiment_df)\n",
    "    sentiment_df.index = df['combined_name'].unique()\n",
    "\n",
    "    # Arbitrarily mark cells whose sentiment scores did not originate from the movie dataframe.\n",
    "    # True sentiment scores cannot be less than 0\n",
    "    sentiment_df = sentiment_df * -10\n",
    "    \n",
    "    # We standardize the length of movies by assigning each line to the index of its relative position in the movie \n",
    "    # (e.g. 66% of the way through) to its position in the expanded standardized movie length\n",
    "    # e.g. if the longest movie had 5000 lines, a line at 66% of the way through its own movie\n",
    "    # would be assigned to position 3300 in its new \"relative\" movie length\n",
    "    for row in df.iterrows():\n",
    "        sentiment_df.loc[row[1]['combined_name'], np.round(row[1]['relative_line_id'] * (expanded_movie_size - 1))] = row[1]['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ne_E4r6IQqgC",
    "outputId": "cc51bd91-68f0-4e6f-a84d-f153e17b6188"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def expand_row(row):\n",
    "    # To allow comparison, we needed to fill in the empty values where character was not speaking. We elected to \n",
    "    # maintain the character's previous sentiment for all non-speaking lines, adding some gaussian noise\n",
    "    row = row.copy()\n",
    "    std = row[row != -10].std()\n",
    "    if row[0] == -10:\n",
    "        first_nonempty_index = row[row != -10].index[0]\n",
    "        first_nonempty_value = row[row != -10].loc[first_nonempty_index]\n",
    "        gaussian_noise = np.random.normal(0, std, size=first_nonempty_index)\n",
    "        row[:first_nonempty_index] = first_nonempty_value + gaussian_noise\n",
    "    for i in range(len(row)):\n",
    "        if row[i] == -10:\n",
    "            gaussian_noise = np.random.normal(0, std)\n",
    "            row[i] = last_val + gaussian_noise\n",
    "        else:\n",
    "            last_val = row[i]\n",
    "    # Standardize each character's arc to have a mean of 0 and a standard deviation of 1\n",
    "    # std = row.std()\n",
    "    # row = (row - row.mean()) / std\n",
    "\n",
    "    return row\n",
    "        \n",
    "if recalculate_all:\n",
    "    sentiment_df = sentiment_df.progress_apply(expand_row, axis=1)\n",
    "    sentiment_df.to_csv(os.path.join(intermediate_path, 'sentiment_df.csv'))\n",
    "else:\n",
    "    sentiment_df = pd.read_csv(os.path.join(intermediate_path, 'sentiment_df.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform principal component analysis for dimensionality reduction to inspect for visible clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Md14fv3lcqp"
   },
   "outputs": [],
   "source": [
    "pca = PCA(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_sentiment_df = sentiment_df.copy().T\n",
    "normalized_sentiment_df = (normalized_sentiment_df - normalized_sentiment_df.mean()) / normalized_sentiment_df.std()\n",
    "normalized_sentiment_df = normalized_sentiment_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For PCA, we use a very small smoothing window (3 timepoints across) to reduce noise\n",
    "rolling_df = normalized_sentiment_df.rolling(3, axis=1).mean().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx8JCARnltbV"
   },
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(pca.fit_transform(rolling_df))\n",
    "pca_df.index = rolling_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the standard deviation of all movies across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "ngXIsMw2nI8U",
    "outputId": "61f62c6b-6871-48cf-f028-fdcef57240d1"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x=sentiment_df.columns, y=sentiment_df.std(), mode='lines'))\n",
    "# fig = go.Scatter()\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"σ of Sentiment\",\n",
    "                  )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist('relative_line_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the average sentiment over time for all characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "MdLqKisIlsWM",
    "outputId": "e7755b30-7b32-481d-909f-3a89500abbbf"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x=sentiment_df.columns, y=sentiment_df.mean().rolling(30).mean(), mode='lines'))\n",
    "# fig = go.Scatter()\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  ) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All characters' first two principal components visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "H_VhoUtDmByW",
    "outputId": "6eb301b0-dcf2-41e4-bb39-307eb7de6eef"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(pca_df.reset_index(), 0, 1, hover_name='index', width=650, height=500)\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"PC0\",\n",
    "    yaxis_title=\"PC1\",\n",
    "\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWDVsNLVRZSZ"
   },
   "source": [
    "#### First Principal Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aG5rveHFa-F2"
   },
   "outputs": [],
   "source": [
    "midpoint = len(sentiment_df) // 2\n",
    "\n",
    "def melt_sentiment_df(df):\n",
    "    return pd.melt(df.reset_index(), id_vars='index').rename({'index': 'Character', 'variable': 'Time', 'value': 'Sentiment'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "B0djLVTEGLF_",
    "outputId": "2c821edc-166a-4da1-a8b3-cfb8f4763467"
   },
   "outputs": [],
   "source": [
    "\n",
    "temp_df = rolling_df.loc[pca_df.sort_values(0).iloc[-5:].index]\n",
    "fig = go.Figure()\n",
    "for index in temp_df.index:\n",
    "    fig.add_trace(go.Scatter(x=temp_df.columns, y=temp_df.loc[index],\n",
    "                    mode='lines'))\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  ) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "-uV2_ppkGmRb",
    "outputId": "3ad82785-9c5a-4acd-fcb1-3f74e241f2f6"
   },
   "outputs": [],
   "source": [
    "temp_df = rolling_df.loc[pca_df.sort_values(0).iloc[midpoint-2:midpoint+3].index]\n",
    "fig = go.Figure()\n",
    "for index in temp_df.index:\n",
    "    fig.add_trace(go.Scatter(x=temp_df.columns, y=temp_df.loc[index],\n",
    "                    mode='lines'))\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  ) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "vazW2rbpGoS3",
    "outputId": "d3b351e0-4364-45de-b3ef-8397e17af19f"
   },
   "outputs": [],
   "source": [
    "temp_df = rolling_df.loc[pca_df.sort_values(0).iloc[:5].index]\n",
    "fig = go.Figure()\n",
    "for index in temp_df.index:\n",
    "    fig.add_trace(go.Scatter(x=temp_df.columns, y=temp_df.loc[index],\n",
    "                    mode='lines'))\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  ) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iX-pF_ngGvpY"
   },
   "source": [
    "#### Second Principal Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "mPrZgCayGq9B",
    "outputId": "70ac7802-14ec-4c97-ba2d-34b8646e19b9"
   },
   "outputs": [],
   "source": [
    "temp_df = rolling_df.loc[pca_df.sort_values(1).iloc[-5:].index]\n",
    "fig = go.Figure()\n",
    "for index in temp_df.index:\n",
    "    fig.add_trace(go.Scatter(x=temp_df.columns, y=temp_df.loc[index],\n",
    "                    mode='lines'))\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  ) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "gw8vhiaHGyKM",
    "outputId": "56c41aa4-dd48-496f-c7ee-2295147eb892"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "temp_df = rolling_df.loc[pca_df.sort_values(1).iloc[midpoint-2:midpoint+3].index]\n",
    "fig = go.Figure()\n",
    "for index in temp_df.index:\n",
    "    fig.add_trace(go.Scatter(x=temp_df.columns, y=temp_df.loc[index],\n",
    "                    mode='lines'))\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "pBCrumWGG8kl",
    "outputId": "e530d298-f89f-4602-bea0-89f8542c96d2"
   },
   "outputs": [],
   "source": [
    "temp_df = rolling_df.loc[pca_df.sort_values(1).iloc[:5].index]\n",
    "fig = go.Figure()\n",
    "for index in temp_df.index:\n",
    "    fig.add_trace(go.Scatter(x=temp_df.columns, y=temp_df.loc[index],\n",
    "                    mode='lines'))\n",
    "fig.update_layout(showlegend=False, \n",
    "                    width=650, \n",
    "                    height=500,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=\"Sentiment\",\n",
    "                  ) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "996EpVT4l5DX",
    "outputId": "b58fd720-68f0-4bc6-f042-77c5e2bec6c8"
   },
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# tsne = TSNE( learning_rate='auto', init='pca')\n",
    "# tsne_df = pd.DataFrame(tsne.fit_transform(sentiment_df.rolling(200, min_periods=1, axis=1).mean().dropna(axis=1)))\n",
    "# tsne_df['ix'] = sentiment_df.index\n",
    "\n",
    "# px.scatter(tsne_df, x=0, y=1, hover_name='ix').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkzFDEWr93dY"
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce noise, we will use a sliding, smoothing window of length 500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one distance metric, we use dynamic time warping, which should be invariant to small translations in the exact timing of patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpzFoG3PcLkZ"
   },
   "outputs": [],
   "source": [
    "if recalculate_all:\n",
    "    from tslearn.metrics import cdist_dtw as dtw\n",
    "    distances = dtw(sentiment_df, n_jobs=-1)\n",
    "\n",
    "    dtw_df = pd.DataFrame(distances)\n",
    "    dtw_df.index = sentiment_df.index\n",
    "    dtw_df.columns = sentiment_df.index\n",
    "\n",
    "    dtw_df.to_csv(os.path.join(intermediate_path, 'distances_markov.csv'))\n",
    "else:\n",
    "    dtw_df = pd.read_csv(os.path.join(intermediate_path, 'distances_markov.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_sentiment_df = sentiment_df.rolling(rolling_window, axis=1, center=True).mean().dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subplot_dimensions(n):\n",
    "    return (int(np.ceil(n / 3)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We settled on 9 clusters as a minimum of the optimal clusterings from all of our models\n",
    "n_clusters=9\n",
    "\n",
    "def cluster(data, model):\n",
    "    \"\"\"\n",
    "    This function helps to calculate and visualize clusters using whatever\n",
    "    clustering model is passed in\n",
    "    \"\"\"\n",
    "    visualizer = KElbowVisualizer(model, k=(2,30), timings=False)\n",
    "    visualizer.fit(data)        # Fit data to visualizer\n",
    "    visualizer.show()\n",
    "    # n_clusters = visualizer.elbow_value_\n",
    "        \n",
    "    model.set_params(n_clusters=n_clusters)\n",
    "    cluster_df = pd.Series(model.fit_predict(data), index=sentiment_df.index)\n",
    "    cluster_df = cluster_df.rename({0: 'cluster'})\n",
    "    clusters = cluster_df.unique()\n",
    "    clusters.sort()\n",
    "    rows, cols = find_subplot_dimensions(n_clusters)\n",
    "    outer_fig = make_subplots(\n",
    "        rows=rows, \n",
    "        cols=cols, \n",
    "        shared_xaxes='all', \n",
    "        shared_yaxes='all',\n",
    "        x_title='Time',\n",
    "        y_title='Sentiment',\n",
    "        horizontal_spacing=0.03,\n",
    "        vertical_spacing=0.05,\n",
    "        subplot_titles=([\"Cluster {}\".format(i) for i in range(n_clusters)])\n",
    "    )\n",
    "    outer_fig.update_layout(showlegend=False, \n",
    "                    width=(cols+1)*200, \n",
    "                    height=(rows+1)*200,\n",
    "                )\n",
    "\n",
    "    \n",
    "    plotted_count = 0\n",
    "    \n",
    "    for i in range(1, rows+1):\n",
    "        for j in range(1, cols+1):\n",
    "            if plotted_count < n_clusters:\n",
    "                indices = cluster_df[cluster_df == plotted_count].dropna().index\n",
    "                temp_df = rolling_sentiment_df.loc[indices]\n",
    "                \n",
    "                # Normalize the data for clean visualizations\n",
    "                temp_df = temp_df.copy().T\n",
    "                temp_df = (temp_df - temp_df.mean()) / temp_df.std()\n",
    "                temp_df = temp_df.T\n",
    "\n",
    "                for index in temp_df.index:\n",
    "                    outer_fig.append_trace(\n",
    "                        go.Scatter(\n",
    "                            x=temp_df.columns, y=temp_df.loc[index],\n",
    "                            mode='lines',\n",
    "                            # text=index, \n",
    "                            marker=dict(\n",
    "                                color='rgba(135, 206, 250, 0.8)',\n",
    "                            ),\n",
    "                            hoverinfo='none',\n",
    "                            ), \n",
    "                        i, \n",
    "                        j)\n",
    "                outer_fig.append_trace(\n",
    "                    go.Scatter(\n",
    "                        x=temp_df.columns, y=temp_df.mean(),\n",
    "                        mode='lines',\n",
    "                        marker=dict(\n",
    "                            color='rgba(128, 128, 128, .8)',\n",
    "                        ),\n",
    "                    ), \n",
    "                    i, \n",
    "                    j\n",
    "                )\n",
    "                plotted_count += 1\n",
    "    outer_fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(\n",
    "        title=dict(\n",
    "            text='Sentiment'\n",
    "        )\n",
    "    )\n",
    "    outer_fig.show()\n",
    "    return cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(base_path, 'clusters_markov.csv')):\n",
    "    clusters_df = pd.DataFrame(index=sentiment_df.index)\n",
    "else:\n",
    "    clusters_df = pd.read_csv(os.path.join(base_path, 'clusters_markov.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering()\n",
    "clusters_df['euclidean_sentiment'] = cluster(rolling_sentiment_df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering(linkage='complete', affinity='manhattan')\n",
    "clusters_df['manhattan_sentiment'] = cluster(rolling_sentiment_df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the differences between each timepoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = rolling_sentiment_df.diff(axis=1).dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering()\n",
    "clusters_df['euclidean_diff'] = cluster(diff_df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering(linkage='complete', affinity='manhattan')\n",
    "clusters_df['manhattan_diff'] = cluster(diff_df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On dynamic time warp distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering(affinity='precomputed', linkage='complete')\n",
    "clusters_df['dtw_sentiment'] = cluster(dtw_df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the gold standard clusterings and standardize their formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard_df = pd.read_json(os.path.join(base_path, 'tvtropes.clusters.json')).T.drop('id', axis=1)\n",
    "gold_standard_df.sort_values('movie')\n",
    "gold_standard_df.to_csv(os.path.join(base_path, 'gold_standard.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'gold_standard_cluster' in clusters_df.columns:\n",
    "    clusters_df['gold_standard_cluster'] = '0' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for loc in clusters_df.index:\n",
    "    if not pd.isna(clusters_df.loc[loc, 'gold_standard_cluster']) and clusters_df.loc[loc, 'gold_standard_cluster'] == '0':\n",
    "        mapping = input(loc)\n",
    "        clusters_df.loc[loc, 'gold_standard_cluster'] = mapping\n",
    "        clusters_df.to_csv(os.path.join(base_path, 'clusters_markov.csv'))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 77 characters who appear in both datasets (have both inferred and gold standard clusterings):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df[~clusters_df['gold_standard_cluster'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Purities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "According to Bamman et al. 2013 cluster purity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "purity_df = clusters_df.copy().dropna()\n",
    "value_counts = purity_df.value_counts('gold_standard_cluster')\n",
    "supported_clusters = value_counts.where(value_counts > 1).dropna().index.to_list()\n",
    "purity_df[purity_df['gold_standard_cluster'].isin(supported_clusters)].value_counts('gold_standard_cluster')\n",
    "\n",
    "clusterings = purity_df.columns.to_list()\n",
    "clusterings.remove('gold_standard_cluster')\n",
    "\n",
    "purities = {}\n",
    "\n",
    "for clustering in clusterings:\n",
    "    purity = pd.crosstab(purity_df[clustering], purity_df['gold_standard_cluster']).max().sum() / len(purity_df)\n",
    "    purities[clustering] = purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline cluster purities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning each character randomly to a cluster based on the proportion of that cluster in the original clustering (According to Bamman et al. 2013 baseline methodology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_distributions_df = pd.DataFrame([clusters_df[clustering].value_counts().sort_index() / len(clusters_df) for clustering in clusterings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "purity_baseline_df = purity_df.copy()\n",
    "for clustering in clusterings:\n",
    "    purity_baseline_df[clustering] = np.random.choice(n_clusters, size=len(purity_baseline_df), p=cluster_distributions_df.loc[clustering])\n",
    "    \n",
    "baseline_purities = {}\n",
    "\n",
    "for clustering in clusterings:\n",
    "    purity = pd.crosstab(purity_baseline_df[clustering], purity_baseline_df['gold_standard_cluster']).max().sum() / len(purity_baseline_df)\n",
    "    baseline_purities[clustering] = purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_purities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for key in baseline_purities:\n",
    "    scores[key] = purities[key] - baseline_purities[key]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_score = np.mean(list(scores.values()))\n",
    "average_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual inspection of gold-standard clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purity_df[purity_df['gold_standard_cluster'].isin(supported_clusters)].value_counts('gold_standard_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoners = purity_df[purity_df['gold_standard_cluster'] == 'stoner'].index.to_list()\n",
    "print(stoners)\n",
    "fig = go.Figure()\n",
    "for stoner in stoners:\n",
    "    temp_df = rolling_sentiment_df.loc[stoner]\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x=temp_df.index, y=temp_df.values,\n",
    "            mode='lines',\n",
    "            # text=index, \n",
    "            marker=dict(\n",
    "                color='rgba(135, 206, 250, 0.8)',\n",
    "            ),\n",
    "            hoverinfo='none',\n",
    "            ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoners = purity_df[purity_df['gold_standard_cluster'] == 'crazy_jealous_guy'].index.to_list()\n",
    "print(stoners)\n",
    "fig = go.Figure()\n",
    "for stoner in stoners:\n",
    "    temp_df = rolling_sentiment_df.loc[stoner]\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x=temp_df.index, y=temp_df.values,\n",
    "            mode='lines',\n",
    "            # text=index, \n",
    "            marker=dict(\n",
    "                color='rgba(135, 206, 250, 0.8)',\n",
    "            ),\n",
    "            hoverinfo='none',\n",
    "            ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoners = purity_df[purity_df['gold_standard_cluster'] == 'stupid_crooks'].index.to_list()\n",
    "print(stoners)\n",
    "fig = go.Figure()\n",
    "for stoner in stoners:\n",
    "    temp_df = rolling_sentiment_df.loc[stoner]\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x=temp_df.index, y=temp_df.values,\n",
    "            mode='lines',\n",
    "            # text=index, \n",
    "            marker=dict(\n",
    "                color='rgba(135, 206, 250, 0.8)',\n",
    "            ),\n",
    "            hoverinfo='none',\n",
    "            ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoners = purity_df[purity_df['gold_standard_cluster'] == 'loveable_rogue'].index.to_list()\n",
    "print(stoners)\n",
    "fig = go.Figure()\n",
    "for stoner in stoners:\n",
    "    temp_df = rolling_sentiment_df.loc[stoner]\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x=temp_df.index, y=temp_df.values,\n",
    "            mode='lines',\n",
    "            # text=index, \n",
    "            marker=dict(\n",
    "                color='rgba(135, 206, 250, 0.8)',\n",
    "            ),\n",
    "            hoverinfo='none',\n",
    "            ))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12b52e57d9ef4bd19f01e0f38d42f3fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1722a5f257aa41b290e59eebe471d4ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1ca4261c3a0b486d8c1a758f350bb94f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fff69c04e2e443f9b13fc4b89b9bd2d",
      "placeholder": "​",
      "style": "IPY_MODEL_45e21e44d94e42f58568633f5572a1e3",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json: "
     }
    },
    "39eee27f778d41f1bc1229863f0da9a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48914257e64644caa249ee54acdd8452",
      "placeholder": "​",
      "style": "IPY_MODEL_c35ffb80167245b58537c52e030a3933",
      "value": " 142k/? [00:00&lt;00:00, 3.93MB/s]"
     }
    },
    "45e21e44d94e42f58568633f5572a1e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48914257e64644caa249ee54acdd8452": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "544a5c3e0c8c4c7ca3b290c9be181746": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a8f1f7ed6044ae187ad67d5e6ecaa82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12b52e57d9ef4bd19f01e0f38d42f3fe",
      "max": 24459,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1722a5f257aa41b290e59eebe471d4ef",
      "value": 24459
     }
    },
    "6fff69c04e2e443f9b13fc4b89b9bd2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "917d2d7d844c463d80927763abef0685": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ca4261c3a0b486d8c1a758f350bb94f",
       "IPY_MODEL_6a8f1f7ed6044ae187ad67d5e6ecaa82",
       "IPY_MODEL_39eee27f778d41f1bc1229863f0da9a8"
      ],
      "layout": "IPY_MODEL_544a5c3e0c8c4c7ca3b290c9be181746"
     }
    },
    "c35ffb80167245b58537c52e030a3933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
